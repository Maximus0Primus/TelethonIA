# TelethonIA - Documentation Technique Compl√®te du Projet

## 1. Vue d'ensemble

### 1.1 Qu'est-ce que TelethonIA ?

TelethonIA est une plateforme d'analyse de memecoins crypto qui :
1. **Collecte** automatiquement les messages de 60+ groupes Telegram de KOLs (Key Opinion Leaders) crypto
2. **Analyse** le sentiment de chaque message avec un pipeline NLP hybride (3 m√©thodes combin√©es)
3. **Extrait** les tokens mentionn√©s ($PEPE, $DOGE, etc.)
4. **Score** chaque token selon plusieurs dimensions (conviction, consensus, momentum, r√©seau)
5. **Affiche** les r√©sultats dans un dashboard Streamlit interactif multi-pages

### 1.2 Probl√®me r√©solu

Les traders crypto qui veulent identifier des opportunit√©s "early" sur les memecoins doivent :
- Suivre 50+ groupes Telegram en parall√®le
- Lire des centaines de messages par jour
- D√©tecter manuellement les consensus entre KOLs
- √âvaluer le sentiment g√©n√©ral sur chaque token

**TelethonIA automatise tout ce processus** et fournit un classement actionnable.

### 1.3 Cible utilisateur

| Segment | Description | Besoin |
|---------|-------------|--------|
| **Crypto-curieux** | Conna√Æt BTC/ETH, veut d√©couvrir les memecoins | Filtrage simple, explications p√©dagogiques |
| **Trader interm√©diaire** | Suit quelques groupes, rate les opportunit√©s | D√©tection de consensus, alertes |
| **Degen light** | Actif mais pas 6h/jour sur TG | Signaux filtr√©s, scoring transparent |

---

## 2. Architecture technique

### 2.1 Structure des fichiers

```
TelethonIA/
‚îú‚îÄ‚îÄ exportfinaljson.py              # Scraper Telegram (collecte)
‚îú‚îÄ‚îÄ ConvictionApp/                  # Application Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py                      # Page d'accueil + configuration
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                    # Coeur du pipeline (1144 lignes)
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_local.py          # Wrapper CryptoBERT
‚îÇ   ‚îú‚îÄ‚îÄ summarizer_deepseek.py      # R√©sum√©s via API DeepSeek
‚îÇ   ‚îú‚îÄ‚îÄ backtest_weights_core.py    # Backtesting (1233 lignes)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ cache/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_keys.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pair_cache.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token_hints.json
‚îÇ   ‚îú‚îÄ‚îÄ data/telegram/              # JSONs export√©s
‚îÇ   ‚îî‚îÄ‚îÄ pages/                      # Pages Streamlit
‚îÇ       ‚îú‚îÄ‚îÄ Dashboard_global.py     # Classement principal
‚îÇ       ‚îú‚îÄ‚îÄ Exploration_visuelle.py # Graphes et heatmaps
‚îÇ       ‚îú‚îÄ‚îÄ Vue_par_groupe.py       # Analyse par groupe
‚îÇ       ‚îú‚îÄ‚îÄ Investissement.py       # Super classement
‚îÇ       ‚îú‚îÄ‚îÄ Backtest_Weights.py     # Optimisation Optuna
‚îÇ       ‚îú‚îÄ‚îÄ Stats_historiques_&_Graph.py
‚îÇ       ‚îî‚îÄ‚îÄ recup_tokens_values.py
‚îú‚îÄ‚îÄ TelethonClient.py               # Setup auth Telegram
‚îú‚îÄ‚îÄ getID.py                        # R√©cup√©ration IDs groupes
‚îú‚îÄ‚îÄ memecoin_dashboard.py           # Dashboard alternatif (heuristique)
‚îî‚îÄ‚îÄ group_cache.json                # Cache IDs groupes
```

### 2.2 Flux de donn√©es

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         COLLECTE                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  exportfinaljson.py                                              ‚îÇ
‚îÇ  ‚îî‚îÄ> Telethon API (GetHistoryRequest)                           ‚îÇ
‚îÇ      ‚îî‚îÄ> 60+ groupes Telegram                                   ‚îÇ
‚îÇ          ‚îî‚îÄ> 50 messages/groupe                                 ‚îÇ
‚îÇ              ‚îî‚îÄ> messages_export_YYYYMMDD_HHMMSS.json           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       PARSING & DEDUP                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  utils.py                                                        ‚îÇ
‚îÇ  ‚îú‚îÄ> parse_messages_json()     # Supporte 2 formats JSON        ‚îÇ
‚îÇ  ‚îú‚îÄ> deduplicate_messages()    # Fusionne exports, √©limine dup  ‚îÇ
‚îÇ  ‚îî‚îÄ> load_many_jsons()         # Charge plusieurs fichiers      ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Colonnes produites :                                            ‚îÇ
‚îÇ  [id, date, group, text, conviction, remark, tokens]            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EXTRACTION TOKENS                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  utils.py                                                        ‚îÇ
‚îÇ  ‚îú‚îÄ> Regex: \$[A-Z][A-Z0-9]{1,14}                               ‚îÇ
‚îÇ  ‚îú‚îÄ> Alias sans $ si contexte crypto d√©tect√©                    ‚îÇ
‚îÇ  ‚îú‚îÄ> Blacklist: TOKEN, COIN, MEME, USD, BTC...                  ‚îÇ
‚îÇ  ‚îî‚îÄ> explode_tokens() : 1 ligne par (message, token)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ANALYSE DE SENTIMENT                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  3 canaux parall√®les :                                           ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  1. VADER (vaderSentiment)                                      ‚îÇ
‚îÇ     ‚îî‚îÄ> Score [-1, +1] bas√© sur lexique anglais                 ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  2. Lexique Crypto (custom, 50+ termes)                         ‚îÇ
‚îÇ     ‚îú‚îÄ> Positifs: "ath" +0.60, "listing" +0.55, "pump" +0.30    ‚îÇ
‚îÇ     ‚îú‚îÄ> N√©gatifs: "rug" -0.80, "scam" -0.75, "exploit" -0.70    ‚îÇ
‚îÇ     ‚îî‚îÄ> Gestion des n√©gateurs ("not bullish" -> flip)           ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  3. CryptoBERT (ElKulako/cryptobert via HuggingFace)            ‚îÇ
‚îÇ     ‚îú‚îÄ> RoBERTa fine-tun√© sur 3.2M messages crypto              ‚îÇ
‚îÇ     ‚îú‚îÄ> Classification: Bullish / Bearish / Neutral             ‚îÇ
‚îÇ     ‚îî‚îÄ> Stretch: tanh(1.8 * arctanh(x)) pour amplifier          ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Fusion :                                                        ‚îÇ
‚îÇ  sentiment = (w_hf*HF + w_vader*VADER + w_crypto*LEX) / sum     ‚îÇ
‚îÇ            + rule_adjustments * gain                             ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Poids par d√©faut: HF=0.50, VADER=0.35, LEX=0.15, gain=1.20     ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Ajustement par conviction groupe :                              ‚îÇ
‚îÇ  w_sentiment = sentiment * (1 + alpha * (conviction - 5) / 10)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SCORING TOKENS                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Plusieurs scores calcul√©s :                                     ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  1. score_conviction (0-10)                                     ‚îÇ
‚îÇ     = alpha * norm(mentions) + (1-alpha) * norm(sentiment)      ‚îÇ
‚îÇ     alpha = 0.6 par d√©faut                                      ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  2. score_quick_win (0-10)                                      ‚îÇ
‚îÇ     = 0.30*sentiment + 0.25*wilson + 0.20*breadth               ‚îÇ
‚îÇ       + 0.15*momentum + 0.10*accel                              ‚îÇ
‚îÇ     * (0.7 + 0.3 * polarisation_inverse)                        ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  3. score_invest (0-10) - page Investissement                   ‚îÇ
‚îÇ     = weighted(avg_score, avg_sent, pagerank, groups_count)     ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  4. super_score (0-10) - mode expert                            ‚îÇ
‚îÇ     = quality + consensus + network + dynamic - polarisation    ‚îÇ
‚îÇ     + bonus persistance optionnel                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ANALYSE GRAPHE                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  graph_edges_advanced() construit 3 types d'ar√™tes :            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  1. group-token : quels groupes parlent de quels tokens         ‚îÇ
‚îÇ  2. token-token : co-mentions dans m√™mes messages               ‚îÇ
‚îÇ     ‚îî‚îÄ> Poids: NPMI (Normalized PMI) + Jaccard                  ‚îÇ
‚îÇ  3. group-group : similarit√© entre groupes                      ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Decay temporel : exp(-age_h / tau)  avec tau=12h par d√©faut    ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  M√©triques extraites :                                           ‚îÇ
‚îÇ  ‚îú‚îÄ> PageRank par token                                         ‚îÇ
‚îÇ  ‚îú‚îÄ> Clusters Louvain                                           ‚îÇ
‚îÇ  ‚îú‚îÄ> Autorit√© groupes                                           ‚îÇ
‚îÇ  ‚îî‚îÄ> Convergence clusters                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    VISUALISATION                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Streamlit multi-pages avec Plotly :                            ‚îÇ
‚îÇ  ‚îú‚îÄ> Tableaux classement                                        ‚îÇ
‚îÇ  ‚îú‚îÄ> Heatmaps (groupes x tokens, temps x tokens)                ‚îÇ
‚îÇ  ‚îú‚îÄ> Bubble charts (sentiment x mentions)                       ‚îÇ
‚îÇ  ‚îú‚îÄ> Bump charts (√©volution des rangs)                          ‚îÇ
‚îÇ  ‚îú‚îÄ> Streamgraphs par cluster                                   ‚îÇ
‚îÇ  ‚îú‚îÄ> Volcano plots (sentiment vs anomalie)                      ‚îÇ
‚îÇ  ‚îú‚îÄ> Sankey diagrams (rank-flow)                                ‚îÇ
‚îÇ  ‚îî‚îÄ> Graphes de r√©seau (NetworkX + PyVis)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. Description d√©taill√©e des pages

### 3.1 Page d'accueil (`app.py`)

**Fonction** : Configuration globale et aper√ßu des donn√©es

**Fonctionnalit√©s** :
- Upload de fichiers JSON (multi-fichiers avec d√©duplication)
- Configuration de la p√©riode d'analyse (2h, 6h, 12h, 24h, 48h, Tout, ou plage personnalis√©e)
- R√©glage des poids de sentiment :
  - Poids mod√®le HuggingFace (CryptoBERT)
  - Poids VADER
  - Poids lexique crypto
  - Gain dynamique (multiplicateur)
- R√©glage des ajustements :
  - Poids des r√®gles/boosts lexicaux
  - Poids conviction de groupe
  - D√©tection alias sans $
- Activation/d√©sactivation du r√©sumeur (DistilBART ou DeepSeek)
- Aper√ßu des messages bruts avec colonnes : date, group, tokens, sentiment, text, remark

**Param√®tres cl√©s** :
```python
use_hf = False          # Activer CryptoBERT
w_hf = 0.50             # Poids HF
w_vader = 0.35          # Poids VADER
w_crypto = 0.15         # Poids lexique
gain_sent = 1.30        # Multiplicateur
rule_weight = 1.0       # Poids r√®gles
group_alpha = 1.0       # Poids conviction groupe
```

---

### 3.2 Dashboard global (`Dashboard_global.py`)

**Fonction** : Classement principal des tokens avec tous les indicateurs

**Fonctionnalit√©s** :

#### KPIs en haut de page
- Nombre de messages
- Nombre de groupes
- Tokens uniques
- Sentiment moyen

#### Classement par token (tableau principal)
Colonnes affich√©es :
| Colonne | Description |
|---------|-------------|
| token | Symbole du token |
| score_conviction | Score 0-10 (mentions + sentiment) |
| score_conviction_graph | Score 0-10 avec renfort graphe |
| score_quick_win | Score 0-10 orient√© trading court terme |
| mentions | Nombre total de mentions |
| breadth | Nombre de groupes uniques |
| sentiment | Sentiment moyen [-1, +1] |
| wilson_low | Borne basse Wilson (confiance) |
| polarisation | D√©saccord entre groupes [0, 1] |
| momentum | Pente r√©cente des mentions |
| accel | Acc√©l√©ration des mentions |
| Autorit√©Groupes | Score d'autorit√© (PageRank groupes) |
| ConvergenceClusters | Multi-cluster coverage |
| Centralit√©PR | PageRank token |
| r√©sum√© | R√©sum√© DeepSeek (si activ√©) |

#### Param√®tres avanc√©s (sidebar)
- Poids mentions vs sentiment (alpha)
- Demi-vie temporelle (tau)
- Seuils NPMI et co-mentions pour le graphe
- Poids Autorit√©/Convergence/Centralit√©

#### Graphiques
- Evolution temporelle du score de conviction (par token)
- D√©tection des flips de sentiment
- D√©tection des newcomers (tokens √©mergents li√©s aux leaders)

---

### 3.3 Exploration visuelle (`Exploration_visuelle.py`)

**Fonction** : Visualisations avanc√©es pour explorer les donn√©es

**Fonctionnalit√©s** :

#### Heatmaps
- **Mentions** : matrice tokens x temps, avec annotations :
  - `‚Ä¢` = z-score > seuil (spike significatif)
  - `‚óÄ‚ñ∂` = flip de sentiment d√©tect√©
- **Sentiment** : m√™me matrice, color√©e RdYlGn

#### Options heatmap
- Top N tokens (5-50)
- Crit√®re de s√©lection : Mentions, Breadth, Spike r√©cent, Score conviction
- Seuil z-score pour cellules significatives
- Tri par clusters (Louvain) optionnel

#### Graphiques optionnels (toggles)
1. **Bubble chart** : Sentiment x Mentions (taille = breadth, couleur = cluster)
2. **Bump chart** : Evolution des rangs dans le temps (top 20)
3. **Streamgraph** : Mentions par cluster empil√©es
4. **Ridgeline** : Distribution des sentiments par token (violon)
5. **Volcano plot** : Sentiment vs z-score anomalie
6. **Rank-flow** : Sankey diagram du top 10 entre fen√™tres

---

### 3.4 Vue par groupe (`Vue_par_groupe.py`)

**Fonction** : Analyse d√©taill√©e groupe par groupe

**Fonctionnalit√©s** :

#### Filtres
- S√©lection du groupe
- S√©lection optionnelle d'un token

#### Affichages
1. **Messages r√©cents** : tableau avec date, tokens, sentiment, text, remark
2. **D√©tail par token** :
   - mentions, sentiment, ci95 (intervalle confiance)
   - score_conviction, mots-cl√©s, r√©sum√©, Sentiment_HF
3. **Top conviction du groupe** : classement intra-groupe

#### Heatmap Groupes x Tokens
- Matrice de score_conviction
- Tri optionnel par clusters (algorithme Louvain sur graphe biparti)

#### Consensus picks
- Tokens pr√©sents dans le Top-K de plusieurs groupes
- Param√®tres : Top-K par groupe, Min groupes
- Colonnes : groups_count, groups_list, avg_score, avg_sent, mentions_total

---

### 3.5 Investissement (`Investissement.py`)

**Fonction** : Classement avanc√© pour d√©cision d'investissement

**Fonctionnalit√©s** :

#### Classement "Investissables"
Tokens remplissant les crit√®res de consensus :
- Pr√©sents dans le Top-K de au moins N groupes
- Sentiment moyen > seuil

Score compos√© :
```
score_invest = weighted(
    avg_score,      # Score intra-groupe moyen
    avg_sent,       # Sentiment moyen inter-groupes
    pagerank,       # Centralit√© r√©seau
    groups_count    # Convergence
)
```

#### Bump chart investissables
Evolution des rangs dans le temps (optionnel)

#### Super Classement (mode expert)
Score composite avanc√© avec 9 composantes :

| Composante | Poids d√©faut | Description |
|------------|--------------|-------------|
| quality_sent | 0.22 | Sentiment moyen normalis√© |
| quality_wilson | 0.12 | Wilson lower bound (confiance) |
| cons_breadth | 0.14 | Couverture inter-groupes |
| cons_groups | 0.10 | Nombre de groupes |
| network_pr | 0.15 | PageRank |
| dyn_mom | 0.17 | Momentum |
| dyn_acc | 0.05 | Acc√©l√©ration |
| stability | 0.10 | 1 - CI95 |
| polar_penalty | 0.15 | P√©nalit√© polarisation |

#### Bonus persistance (optionnel)
R√©compense les tokens rest√©s longtemps dans le haut du classement :
- Fen√™tre configurable (6h - 168h)
- Top-R seuil (3-10)
- Mode additif ou multiplicatif

---

### 3.6 Backtest & Weights (`Backtest_Weights.py`)

**Fonction** : Optimisation des poids avec backtesting

**Fonctionnalit√©s** :

#### Sources de donn√©es
1. **Construction automatique** depuis l'app
2. **Upload CSV** (signals_features.csv + prices.csv)

#### Association tokens -> contrats
√âditeur pour renseigner :
- chainId (solana, ethereum, base, bsc...)
- Contract address (CA)
- Pair/pool address (prioritaire)

Cache des hints persistant

#### Sources de prix
1. **Saisie manuelle** (√©diteur avec template)
2. **Contrats/pools saisis**
3. **Automatique** (Dexscreener -> GeckoTerminal)
4. **Upload prices.csv**
5. **API Birdeye / CoinGecko Pro**

#### Features s√©lectionnables
- score_conviction_graph
- score_conviction
- score_quick_win
- pagerank, breadth, polarisation
- wilson_low, momentum, accel
- mentions, sentiment

#### Optimisation Optuna
- Mode s√©lection : threshold ou top-N
- Horizons configurables (mid=30j, long=90j)
- M√©trique : winrate ou median_return
- Walk-forward avec N folds

#### Outputs
- Meilleurs poids trouv√©s
- Trades s√©lectionn√©s
- Diagnostics par fold
- Export CSV + JSON config

---

## 4. Pipeline de sentiment (d√©tail)

### 4.1 VADER

Librairie `vaderSentiment` qui calcule un score [-1, +1] bas√© sur :
- Lexique de 7500+ mots annot√©s
- R√®gles pour ponctuation, majuscules, emojis basiques
- Bon pour l'anglais g√©n√©ral, moins pour le slang crypto

### 4.2 Lexique crypto custom

50+ termes avec scores manuels :

```python
CRYPTO_LEXICON = {
    # Tr√®s positifs
    "ath": 0.60, "all time high": 0.60, "mooning": 0.55,
    "listing": 0.55, "listed": 0.55, "cex listing": 0.55,

    # Positifs
    "bullish": 0.50, "pump": 0.30, "moon": 0.40,
    "audit passed": 0.45, "renounced": 0.40,

    # N√©gatifs
    "rug": -0.80, "rugged": -0.80, "rugpull": -0.80,
    "scam": -0.75, "scammer": -0.75,
    "exploit": -0.70, "hacked": -0.70,
    "dump": -0.50, "dumping": -0.50,
    "high tax": -0.35, "honeypot": -0.70,

    # Neutres avec contexte
    "dyor": 0.0, "nfa": 0.0,
}
```

Gestion des n√©gateurs :
```python
NEGATORS = ["not", "no", "isn't", "aren't", "wasn't", "weren't",
            "don't", "doesn't", "didn't", "won't", "wouldn't",
            "can't", "couldn't", "shouldn't", "never"]
# Si n√©gateur dans les 3 mots pr√©c√©dents -> flip le signe
```

### 4.3 CryptoBERT

Mod√®le `ElKulako/cryptobert` sur HuggingFace :
- Base : RoBERTa (125M param√®tres)
- Fine-tun√© sur 3.2M messages crypto (Twitter, Reddit, StockTwits, Telegram)
- Classification : Bullish / Bearish / Neutral

Traitement dans `sentiment_local.py` :
1. Tokenization avec troncation √† 512 tokens
2. Inference en batch
3. Conversion score [0,1] -> [-1, +1]
4. Stretch : `tanh(1.8 * arctanh(x))` pour amplifier les signaux faibles

Boosters d'intensit√© :
- CAPS ratio >= 45% : +0.08
- `!` ou `!!!` : +0.03 par `!` (max 0.12)
- Mots positifs/n√©gatifs du lexique : +/-0.05
- Sarcasme ("lol" + n√©gatif) : att√©nue x0.85

### 4.4 Fusion finale

```python
# Scores individuels [-1, +1]
s_vader = vader_analyzer.polarity_scores(text)["compound"]
s_crypto = calculate_crypto_lexicon_score(text)
s_hf = cryptobert_score(text)

# Blend pond√©r√©
w_sum = w_vader + w_crypto + w_hf
sentiment = (w_vader * s_vader + w_crypto * s_crypto + w_hf * s_hf) / w_sum

# Ajustements par r√®gles
for word in positive_words:
    if word in text.lower():
        sentiment += 0.05 * rule_weight

for word in negative_words:
    if word in text.lower():
        sentiment -= 0.07 * rule_weight

# Gain dynamique
sentiment = sentiment * gain  # gain = 1.20 par d√©faut

# Ajustement par conviction du groupe (6-10)
conviction = message["conviction"]  # Score KOL
w_sentiment = sentiment * (1 + group_alpha * (conviction - 5) / 10)
```

---

## 5. Syst√®me de scoring

### 5.1 Score de conviction (base)

```python
# Normalisation
mentions_norm = mentions / max_mentions  # [0, 1]
sentiment_norm = (sentiment + 1) / 2      # [-1,1] -> [0,1]

# Score [0, 10]
alpha = 0.6  # Poids mentions vs sentiment
score_conviction = 10 * (alpha * mentions_norm + (1-alpha) * sentiment_norm)
```

### 5.2 Score Quick Win

Orient√© trading court terme, p√©nalise la polarisation :

```python
# Composantes normalis√©es [0, 1]
sent01 = (sentiment + 1) / 2
wil01 = wilson_low.clip(0, 1)
br01 = (breadth / max_breadth).clip(0, 1)
mom01 = (momentum / max_momentum / 2 + 0.5).clip(0, 1)
acc01 = (accel / max_accel / 2 + 0.5).clip(0, 1)
pol01_inv = 1 - polarisation.clip(0, 1)

# Combinaison
quick = (0.30 * sent01 +
         0.25 * wil01 +
         0.20 * br01 +
         0.15 * mom01 +
         0.10 * acc01)

# P√©nalit√© polarisation
quick = quick * (0.7 + 0.3 * pol01_inv)

score_quick_win = 10 * quick
```

### 5.3 Score Investissement

Bas√© sur le consensus inter-groupes :

```python
# Apr√®s consensus_table() : tokens dans Top-K de >= N groupes
score_norm = avg_score / 10           # [0, 1]
sent_norm = (avg_sent + 1) / 2        # [0, 1]
groups_norm = groups_count / max_groups  # [0, 1]
pr_norm = pagerank_normalized         # [0, 1]

# Poids configurables
w_score, w_sent, w_pr, w_groups = 0.35, 0.25, 0.20, 0.20

score_invest = 10 * (
    w_score * score_norm +
    w_sent * sent_norm +
    w_pr * pr_norm +
    w_groups * groups_norm
) / (w_score + w_sent + w_pr + w_groups)
```

### 5.4 Super Score (expert)

9 composantes + bonus optionnel :

```python
# Composantes positives (toutes normalis√©es 0-1)
quality = w_sent * nz_sent + w_wilson * nz_wilson
consensus = w_breadth * nz_breadth + w_groups * nz_groups
network = w_pr * nz_pagerank
dynamic = w_mom * nz_momentum + w_acc * nz_accel
stability = w_stab * (1 - ci95)

# P√©nalit√©
penalty = w_polar * nz_polarisation

# Score de base
super_score = 10 * (
    (quality + consensus + network + dynamic + stability) / sum_weights
    - penalty / (penalty_weight + sum_weights)
)

# Bonus persistance (optionnel)
if use_persist:
    persist_frac = fraction_of_bins_in_top_R
    if multiplicative:
        super_score *= (1 + w_persist * persist_frac * (1 + gain))
    else:
        super_score += 10 * w_persist * (1 + gain) * persist_frac
```

---

## 6. Donn√©es des KOLs

### 6.1 Liste des 60+ groupes Telegram

Chaque groupe a un score de conviction (6-10) et des remarques :

| Score | Groupes | Caract√©ristiques |
|-------|---------|------------------|
| **10/10** | overdose_gems_calls, cryptorugmuncher, thetonymoontana | Winrate extr√™me, conviction maximale |
| **9/10** | marcellcooks, PoseidonTAA, Carnagecalls, MarkGems | Tr√®s peu de calls mais tr√®s bons |
| **8/10** | ghastlygems, slingdeez, archercallz, LevisAlpha, darkocalls... | Bonne conviction, diff√©rents styles |
| **7/10** | shahlito, sadcatgamble, veigarcalls, Luca_Apes... | Plus de calls, moins long terme |
| **6/10** | houseofdegeneracy | Int√©ressant mais moins fort |

### 6.2 Synergies entre groupes

Certains groupes sont li√©s et doivent √™tre consid√©r√©s ensemble :
- **LevisAlpha + dylansdegens + jsdao** : si en lien, signal fort
- **shahlito + marcellcooks** : si en lien, tr√®s bien
- **BossmanCallsOfficial** : √† croiser avec Levis, Dylans, Shas, Marcell

### 6.3 Groupes sp√©ciaux

- **cryptorugmuncher** (10/10) : Explique les rugs et scams - signaux **n√©gatifs** √† int√©grer
- **thetonymoontana** (10/10) : Projets communautaires, souvent bullish
- **PoseidonTAA** (9/10) : Orient√© analyses techniques

---

## 7. Fonctionnalit√©s de d√©tection

### 7.1 Flips de sentiment

D√©tection quand un token passe de n√©gatif √† positif (ou inverse) :

```python
def flip_detector(df, win_h=12, thr=0.1):
    mid = now - timedelta(hours=win_h)
    s_before = sentiment[date < mid].mean()
    s_after = sentiment[date >= mid].mean()

    # Flip si franchissement du seuil
    if (s_before < -thr and s_after > +thr) or \
       (s_before > +thr and s_after < -thr):
        return True
```

### 7.2 Newcomers

Tokens r√©cemment apparus et li√©s aux leaders :

```python
def newcomers(df, hours_recent=24, top_k_leaders=5, npmi_min=0.1):
    # Leaders = top tokens par mentions
    leaders = top_tokens(df, k=top_k_leaders)

    # Tokens vus pour la premi√®re fois dans les N derni√®res heures
    first_seen = df.groupby("token")["date"].min()
    candidates = first_seen[first_seen >= cutoff]

    # Garder ceux avec forte co-mention (NPMI) avec un leader
    for token in candidates:
        npmi_with_leaders = max(npmi(token, leader) for leader in leaders)
        if npmi_with_leaders >= npmi_min:
            yield token
```

### 7.3 Consensus inter-groupes

Token mentionn√© dans le Top-K de plusieurs groupes :

```python
def consensus_table(scores, top_k=5, min_groups=2):
    # Garder Top-K par groupe
    topk = scores[scores["rank_in_group"] <= top_k]

    # Agr√©ger par token
    consensus = topk.groupby("token").agg(
        groups_count = nunique("group"),
        groups_list = list("group"),
        avg_sent = mean("sentiment"),
        avg_score = mean("score_conviction")
    )

    # Filtrer par minimum de groupes
    return consensus[consensus["groups_count"] >= min_groups]
```

---

## 8. APIs et int√©grations externes

### 8.1 Telegram (Telethon)

- **Authentification** : api_id + api_hash + phone
- **M√©thode** : `GetHistoryRequest(limit=50)` par groupe
- **Rate limiting** : 1 seconde entre requ√™tes (basique)
- **Session** : Fichier `.session` pour persistance

### 8.2 DeepSeek (r√©sum√©s)

- **Endpoint** : `https://api.deepseek.com/v1/chat/completions`
- **Mod√®le** : deepseek-chat
- **Format de sortie** structur√© :
  1. Description (type + fonction)
  2. Catalyseurs (2-4 bullets)
  3. Risques (2-4 bullets)
  4. Sentiment global (Optimiste/Prudent/N√©gatif)

### 8.3 Prix des tokens

Plusieurs sources support√©es :

| Source | Usage | Limite |
|--------|-------|--------|
| **Dexscreener** | Recherche paires | Rate limit mod√©r√© |
| **GeckoTerminal** | OHLCV historique | Pagination |
| **Birdeye** | Solana principalement | API key requise |
| **CoinGecko Pro** | Coins list√©s | API key requise |

Caches impl√©ment√©s :
- `pair_cache.json` : Association token -> paire (TTL 7j)
- `ohlcv/` : Donn√©es OHLCV (TTL 3j)
- `token_hints.json` : Mappings manuels

---

## 9. Configuration et param√®tres

### 9.1 Session state Streamlit

Tous les param√®tres sont persist√©s entre les pages via `st.session_state` :

```python
# P√©riode
period = "24h"
use_custom_period = False
custom_start_date, custom_start_time = None, None
custom_end_date, custom_end_time = None, None

# Sentiment
use_hf = False
w_hf, w_vader, w_crypto = 0.50, 0.35, 0.15
gain_sent = 1.30
rule_weight = 1.0
group_alpha = 1.0
alias_no_dollar = True

# Scoring
mentions_alpha = 0.6
tau_hours = 12.0

# Graphe
score_graph_on = True
gamma_struct = 0.30
wA, wC, wPRT = 0.60, 0.40, 0.20
npmi_min_sc = 0.10
min_cooc_sc = 3

# Donn√©es
RAW_ALL = pd.DataFrame()  # Dataset brut fusionn√©
RAW_DF = pd.DataFrame()   # Dataset avec sentiment calcul√©
```

### 9.2 Fichiers de cache

```
cache/
‚îú‚îÄ‚îÄ api_keys.json       # Cl√©s API (√† s√©curiser!)
‚îú‚îÄ‚îÄ pair_cache.json     # {token: {chain, address, pair}}
‚îú‚îÄ‚îÄ token_hints.json    # Mappings manuels user
‚îî‚îÄ‚îÄ ohlcv/              # Donn√©es OHLCV par token
    ‚îú‚îÄ‚îÄ PEPE_solana.parquet
    ‚îî‚îÄ‚îÄ ...
```

---

## 10. Probl√®mes connus et am√©liorations pr√©vues

### 10.1 Probl√®mes critiques

1. **S√©curit√©** : API keys hardcod√©es dans le code
2. **Pas de git** : Aucun versioning
3. **Pas de tests** : Aucun test unitaire

### 10.2 Probl√®mes techniques

1. **Performance** : CryptoBERT recalcule √† chaque changement de filtre
2. **Scalabilit√©** : O(n¬≤) pour le graphe groupe-groupe
3. **Rate limiting** : Trop basique pour Telegram

### 10.3 Am√©liorations planifi√©es

1. **Nouvelle app clean** avec uniquement les meilleures fonctionnalit√©s
2. **Int√©gration API prix** (vs ATH, volume, holders)
3. **Backtesting avanc√©** avec XGBoost + Optuna
4. **Si succ√®s** : Migration vers Next.js + Supabase + Stripe

---

## 11. Annexes

### 11.1 D√©pendances principales

```
streamlit>=1.36
pandas>=2.0
numpy>=1.25
plotly>=5.22
vaderSentiment>=3.3.2
transformers>=4.40
torch>=2.2
networkx>=3.2
telethon>=1.28
```

### 11.2 Commandes utiles

```bash
# Lancer l'app
cd ConvictionApp
streamlit run app.py

# Exporter les messages Telegram
python exportfinaljson.py

# Voir les IDs des groupes
python getID.py
```

### 11.3 Format JSON d'export

```json
{
  "GroupName": [
    {
      "id": 12345,
      "date": "2024-01-15T14:30:00",
      "text": "üöÄ $PEPE looking bullish, might moon soon",
      "conviction": 8,
      "remark": "tr√®s bonne conviction"
    }
  ]
}
```

ou format plat :

```json
[
  {
    "id": 12345,
    "date": "2024-01-15T14:30:00",
    "group": "GroupName",
    "text": "üöÄ $PEPE looking bullish",
    "conviction": 8,
    "remark": "..."
  }
]
```
