telethon>=1.36.0
vaderSentiment>=3.3.2
supabase>=2.0.0
python-dotenv>=1.0.0
requests>=2.31.0
xgboost>=2.0.0
lightgbm>=4.2.0
optuna>=3.5.0
pandas>=2.1.0
numpy>=1.26.0
scikit-learn>=1.4.0
shap>=0.44.0
joblib>=1.3.0
pandas-ta>=0.3.14b
# Optional: CryptoBERT sentiment (better accuracy, needs ~2GB VRAM/RAM)
# transformers>=4.40.0
# torch>=2.2.0
# Optional: Semantic narrative classification (22MB model, CPU only)
# sentence-transformers>=3.0.0
